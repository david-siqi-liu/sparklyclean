<?xml version="1.0" encoding="UTF-8"?>

<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.davidsiqiliu</groupId>
    <artifactId>SparklyClean</artifactId>
    <version>1.0-SNAPSHOT</version>
    <description>Data Cleaning using Apache Spark</description>
    <name>SparklyClean</name>
    <url>https://github.com/david-siqi-liu/sparklyclean</url>

    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <scala.version>2.11.8</scala.version>
        <hbase.version>1.2.6</hbase.version>
        <hadoop.version>3.0.3</hadoop.version>
        <spark.version>2.3.1</spark.version>
    </properties>

    <dependencies>
        <dependency>
            <groupId>com.github.vickumar1981</groupId>
            <artifactId>stringdistance_2.12</artifactId>
            <version>1.1.4</version>
        </dependency>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>4.12</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>${hadoop.version}</version>
        </dependency>
<!--        <dependency>-->
<!--            <groupId>org.apache.hbase</groupId>-->
<!--            <artifactId>hbase-client</artifactId>-->
<!--            <version>${hbase.version}</version>-->
<!--        </dependency>-->
<!--        <dependency>  &lt;!&ndash; Needed for using MapReduce w/ HBase &ndash;&gt;-->
<!--            <groupId>org.apache.hbase</groupId>-->
<!--            <artifactId>hbase-server</artifactId>-->
<!--            <version>${hbase.version}</version>-->
<!--        </dependency>-->
<!--        <dependency>-->
<!--            <groupId>args4j</groupId>-->
<!--            <artifactId>args4j</artifactId>-->
<!--            <version>2.33</version>-->
<!--        </dependency>-->
<!--        <dependency>-->
<!--            <groupId>tl.lin</groupId>-->
<!--            <artifactId>lintools-datatypes</artifactId>-->
<!--            <version>1.1.1</version>-->
<!--        </dependency>-->
<!--        <dependency>-->
<!--            <groupId>net.sf.jung</groupId>-->
<!--            <artifactId>jung-api</artifactId>-->
<!--            <version>2.1.1</version>-->
<!--        </dependency>-->
<!--        <dependency>-->
<!--            <groupId>net.sf.jung</groupId>-->
<!--            <artifactId>jung-algorithms</artifactId>-->
<!--            <version>2.1.1</version>-->
<!--        </dependency>-->
<!--        <dependency>-->
<!--            <groupId>net.sf.jung</groupId>-->
<!--            <artifactId>jung-graph-impl</artifactId>-->
<!--            <version>2.1.1</version>-->
<!--        </dependency>-->
<!--        <dependency>-->
<!--            <groupId>com.google.guava</groupId>-->
<!--            <artifactId>guava</artifactId>-->
<!--            <version>23.6-jre</version>-->
<!--        </dependency>-->
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <version>${scala.version}</version>
        </dependency>
        <dependency>
            <groupId>org.scalatest</groupId>
            <artifactId>scalatest_2.11</artifactId>
            <version>3.0.4</version>
        </dependency>
        <dependency>
            <groupId>org.rogach</groupId>
            <artifactId>scallop_2.11</artifactId>
            <version>3.1.1</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_2.11</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_2.11</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_2.11</artifactId>
            <version>${spark.version}</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.7.0</version>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                </configuration>
            </plugin>

            <plugin>
                <groupId>org.scala-tools</groupId>
                <artifactId>maven-scala-plugin</artifactId>
                <version>2.15.2</version>
                <executions>
                    <execution>
                        <phase>process-resources</phase>
                        <goals>
                            <goal>add-source</goal>
                            <goal>compile</goal>
                        </goals>
                    </execution>
                    <execution>
                        <id>scala-test-compile</id>
                        <phase>process-test-resources</phase>
                        <goals>
                            <goal>testCompile</goal>
                        </goals>
                    </execution>
                </executions>
                <configuration>
                    <scalaVersion>${scala.version}</scalaVersion>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <version>3.1.0</version>
                <executions>
                    <execution>
                        <phase>package</phase>
                        <goals>
                            <goal>shade</goal>
                        </goals>
                        <configuration>
                            <createDependencyReducedPom>false</createDependencyReducedPom>
                            <!-- This is an Mac OSX issue because the default filesystem is case-insensitive,
                                 so multiple versions of files (w/ different cases) clash when Hadoop tries
                                 to unpack the jar. -->
                            <filters>
                                <filter>
                                    <artifact>*:*</artifact>
                                    <excludes>
                                        <exclude>META-INF/*.SF</exclude>
                                        <exclude>META-INF/*.DSA</exclude>
                                        <exclude>META-INF/*.RSA</exclude>
                                        <exclude>META-INF/LICENSE*</exclude>
                                        <exclude>license/*</exclude>
                                    </excludes>
                                </filter>
                            </filters>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>

</project>
